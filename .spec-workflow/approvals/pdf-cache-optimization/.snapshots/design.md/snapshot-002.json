{
  "id": "snapshot_1767779075933_zir37qzof",
  "approvalId": "approval_1767778923246_jcqb4sc7o",
  "approvalTitle": "设计文档: PDF缓存处理优化",
  "version": 2,
  "timestamp": "2026-01-07T09:44:35.933Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# 设计文档: PDF缓存处理优化\n\n## 概述\n\n本设计通过引入缓存机制将PDF处理流程拆分为两阶段（图片提取 + API调用），提升系统可靠性并优化日志输出。核心原则是**最小化新增代码，最大化复用现有函数**，保持向后兼容性。\n\n关键改进：\n- 将 `process_pdf` 改造为支持双模式（完整模式/仅提取模式）\n- 新增 `process_from_cache` 从缓存读取图片并调用API\n- 新增 `archive_cache` 自动归档提取的图片\n- 优化API调用日志，移除base64编码内容\n- 支持独立执行第二阶段（失败重试）\n\n## 技术栈与架构对齐\n\n### 技术栈延续\n- **Python 3.12+** - 保持现有版本\n- **OpenAI API** - 通过 OpenAI 客户端调用 Gemini 3 Flash\n- **pdf2image** - PDF转图片（已在使用）\n- **Pillow (PIL)** - 图片处理（已在使用）\n- **Pandas** - 数据处理（已在使用）\n\n### 架构原则\n1. **单一职责**：每个函数职责清晰\n   - `process_pdf`: 负责PDF到图片的提取\n   - `process_from_cache`: 负责从缓存调用API\n   - `archive_cache`: 负责cache归档\n\n2. **模块化设计**：缓存逻辑与PDF处理逻辑解耦\n3. **配置驱动**：所有参数通过 config.json 配置\n4. **最小侵入**：不破坏现有主流程，新增模式参数\n\n## 代码复用分析\n\n### 现有组件复用\n\n1. **encode_images_to_base64** (processing.py)\n   - 复用：在 `process_from_cache` 中编码图片\n   - 无需修改：已支持JPEG格式和质量参数\n\n2. **build_vision_payload** (processing.py)\n   - 复用：构建API请求payload\n   - 无需修改：通用函数\n\n3. **call_vision_api** (processing.py)\n   - 复用：实际API调用\n   - 需要修改：优化日志输出（需求1）\n\n4. **convert_pdf_to_images** (processing.py)\n   - 复用：PDF转图片逻辑\n   - 无需修改：已支持DPI和格式参数\n\n5. **get_page_count** (processing.py)\n   - 复用：统计PDF页数\n   - 无需修改：简单功能函数\n\n6. **批次管理 (state.json)**\n   - 复用：现有的批次号管理\n   - 需要增强：添加cache归档记录\n\n### 需要删除的过时组件\n1. **get_smart_pages_to_process** (processing.py)\n   - 删除：智能选页逻辑已被简化\n\n2. **页面筛选配置** (config.json)\n   - 删除：page_filtering 配置块\n\n## 架构设计\n\n### 处理流程图\n\n```mermaid\ngraph TD\n    A[PDF文件] --> B{处理模式}\n    B -->|full/自动| C[process_pdf extract_only]\n    B -->|process_from_cache| D[读取cache参数]\n\n    C --> E{提取成功?}\n    E -->|是| F[返回cache信息]\n    E -->|否| G[记录错误 & 移动PDF]\n\n    F --> H[process_from_cache]\n    D --> H\n\n    H --> I{API调用成功?}\n    I -->|是| J[archive_cache]\n    I -->|否| K[保留cache & 记录失败]\n\n    J --> L{归档成功?}\n    L -->|是| M[更新state.json]\n    L -->|否| N[保留cache & 记录警告]\n\n    M --> O[处理完成]\n    N --> O\n    G --> O\n    K --> O\n```\n\n### 核心组件设计\n\n#### 1. 改造后的 `process_pdf` 函数\n\n**位置**: `/home/thelya/Work/data/processing.py`\n\n```python\ndef process_pdf(\n    pdf_path: str,\n    client,\n    config: Dict[str, Any],\n    system_prompt: str,\n    mode: str = \"full\"\n) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    PDF处理主函数，支持双模式\n\n    Args:\n        pdf_path: PDF文件路径\n        client: OpenAI客户端\n        config: 配置字典\n        system_prompt: 系统提示词\n        mode: 处理模式\n            - \"full\": 完整处理（向后兼容）\n            - \"extract_only\": 仅提取图片到cache\n\n    Returns:\n        mode=\"extract_only\": {\"cache_dir\": str, \"image_paths\": List[str]}\n        mode=\"full\": {\"result\": Dict, \"cache_dir\": str}\n        失败: None\n    \"\"\"\n```\n\n**关键改动**:\n- 新增 `mode` 参数（默认\"full\"保持向后兼容）\n- 统一返回字典格式（不再是元组）\n- 内部实现分两阶段：提取图片 → 调用API\n- 自动保存图片到 `./cache/{pdf_name}/`\n- 支持配置最大页数限制（`max_pages`）\n\n**页数处理逻辑**:\n```python\nmax_pages = config.get('processing_settings', {}).get('max_pages', 25)\npage_count = get_page_count(pdf_path)\n\nif page_count > max_pages:\n    logger.warning(f\"PDF页数({page_count})超过最大限制({max_pages})，只处理前{max_pages}页\")\n    pages_to_process = list(range(1, max_pages + 1))\nelse:\n    # 原逻辑：处理除最后一页外的所有页\n    if page_count > 1:\n        pages_to_process = list(range(1, page_count))\n    else:\n        pages_to_process = [1]\n```\n\n#### 2. 新增的 `process_from_cache` 函数\n\n**位置**: `/home/thelya/Work/data/processing.py`\n\n```python\ndef process_from_cache(\n    cache_dir: str,\n    pdf_name: str,\n    image_paths: List[str],\n    client,\n    config: Dict[str, Any],\n    system_prompt: str\n) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    第二阶段：从cache读取图片并调用API\n\n    Args:\n        cache_dir: cache目录路径（用于日志）\n        pdf_name: PDF文件名（用于归档）\n        image_paths: 图片文件路径列表\n        client: OpenAI客户端\n        config: 配置字典\n        system_prompt: 系统提示词\n\n    Returns:\n        提取的数据字典\n    \"\"\"\n```\n\n**关键实现**:\n- 从指定路径读取图片文件\n- 复用 `encode_images_to_base64` 进行编码\n- 复用 `build_vision_payload` 构建请求\n- 复用 `call_vision_api` 调用API\n- 失败时返回None并记录详细错误\n\n#### 3. 新增的 `archive_cache` 函数\n\n**位置**: `/home/thelya/Work/data/processing.py` 或 `main.py`\n\n```python\ndef archive_cache(\n    cache_dir: str,\n    pdf_name: str,\n    batch_number: int,\n    archive_base: str\n) -> Optional[str]:\n    \"\"\"\n    将cache目录归档到指定位置\n\n    Args:\n        cache_dir: cache目录路径\n        pdf_name: PDF文件名（用于命名zip文件）\n        batch_number: 批次号\n        archive_base: 归档根目录\n\n    Returns:\n        归档文件路径（成功）或 None（失败）\n    \"\"\"\n```\n\n**关键实现**:\n- 时间戳格式化：`YYYY-MM-DD`\n- 批次目录：`Dataset ({batch_number}) {date}/`\n- Zip文件名：`{pdf_name}_images.zip`\n- 异常处理：zip创建失败、rmtree失败\n- 失败时保留cache目录\n\n**归档路径示例**:\n```\n/mnt/e/Documents/data_extracted/Dataset (15) 2025-03-25/\n├── paper1_images.zip\n├── paper2_images.zip\n└── ...\n```\n\n#### 4. 优化的 `call_vision_api` 函数\n\n**位置**: `/home/thelya/Work/data/processing.py`（已有函数修改）\n\n**日志优化前**:\n```python\nlogger.debug(f\"请求payload: {payload}\")  # 包含base64编码，日志巨大\nlogger.debug(f\"完整响应内容: {content}\")  # 响应内容可能很大\n```\n\n**优化后**:\n```python\n# 第963行（大约）\nimage_count = len([item for item in payload[\"messages\"][1][\"content\"] if item[\"type\"] == \"image_url\"])\nlogger.debug(f\"API请求 - 模型: {model_name}, 图片: {image_count}, max_tokens: {max_tokens}\")\n\n# 第975行（大约）\nlogger.debug(f\"API响应长度: {len(content)} 字符\")\nif len(content) > 1000:\n    logger.debug(f\"响应预览: {content[:500]}...\")\nelse:\n    logger.debug(f\"完整响应内容: {content}\")\n```\n\n#### 5. 主流程更新 (`main.py`)\n\n**位置**: `/home/thelya/Work/data/main.py`\n\n**自动流程**（处理新PDF）:\n```python\n# 阶段1: 提取图片\ncache_result = process_pdf(file_path, client, config, SYSTEM_PROMPT, mode=\"extract_only\")\n\nif cache_result:\n    cache_info = cache_result\n    cache_dir = cache_info[\"cache_dir\"]\n    image_paths = cache_info[\"image_paths\"]\n    pdf_name = os.path.splitext(os.path.basename(file_path))[0]\n\n    # 阶段2: 调用API\n    result = process_from_cache(cache_dir, pdf_name, image_paths, client, config, SYSTEM_PROMPT)\n\n    if result:\n        # 阶段3: 归档\n        archive_path = archive_cache(cache_dir, pdf_name, state[\"batch_number\"],\n                                   config[\"paths\"][\"archive_destination\"])\n        if archive_path:\n            logger.info(f\"归档成功: {archive_path}\")\n        else:\n            logger.warning(f\"归档失败，保留cache: {cache_dir}\")\n    else:\n        logger.error(f\"API处理失败: {pdf_name}\")\n        # 失败处理（移动PDF到NotInput）\nelse:\n    logger.error(f\"图片提取失败: {file_path}\")\n    # 失败处理（移动PDF到NotInput）\n```\n\n**独立第二阶段流程**:\n```python\nif mode == \"process_from_cache\":\n    # 命令行参数指定 cache_dir\n    cache_dir = args.cache_dir\n    pdf_name = args.pdf_name\n\n    # 扫描cache目录下的所有jpg文件\n    image_paths = sorted([\n        os.path.join(cache_dir, f)\n        for f in os.listdir(cache_dir)\n        if f.endswith('.jpg')\n    ])\n\n    result = process_from_cache(cache_dir, pdf_name, image_paths, client, config, SYSTEM_PROMPT)\n\n    if result:\n        # 检查是否已归档（避免重复）\n        archive_base = config[\"paths\"][\"archive_destination\"]\n        # ...归档逻辑...\n```\n\n#### 6. 命令行参数设计\n\n**新参数**:\n- `--mode`: 运行模式（\"full\" | \"extract_only\" | \"process_from_cache\"）\n- `--cache_dir`: cache目录路径（process_from_cache模式时必需）\n- `--pdf_name`: PDF文件名（process_from_cache模式时必需）\n\n**使用示例**:\n```bash\n# 完整流程（默认）\npython main.py --mode full\n\n# 仅提取图片\npython main.py --mode extract_only\n\n# 从cache处理（重试）\npython main.py --mode process_from_cache --cache_dir ./cache/paper1 --pdf_name paper1\n```\n\n## 数据模型\n\n### Cache 数据结构\n\n**目录结构**:\n```\n./cache/\n└── {pdf_name}/\n    ├── 1.jpg\n    ├── 2.jpg\n    ├── ...\n    └── metadata.json  # 可选：存储页数、提取时间等\n```\n\n**元数据 (metadata.json)**:\n```json\n{\n  \"pdf_name\": \"paper1\",\n  \"page_count\": 12,\n  \"pages_processed\": 11,\n  \"extract_timestamp\": \"2025-03-25T10:30:00Z\",\n  \"image_dpi\": 150,\n  \"image_format\": \"JPEG\",\n  \"image_quality\": 95\n}\n```\n\n### State.json 扩展\n\n**新增字段**:\n```json\n{\n  \"batch_number\": 15,\n  \"archived_caches\": [\n    {\n      \"pdf_name\": \"paper1\",\n      \"cache_dir\": \"./cache/paper1\",\n      \"archive_path\": \"/mnt/e/Documents/data_extracted/Dataset (15) 2025-03-25/paper1_images.zip\",\n      \"timestamp\": \"2025-03-25T10:45:00Z\"\n    }\n  ]\n}\n```\n\n## 错误处理策略\n\n### 错误场景与处理\n\n#### 1. 图片提取失败\n**场景**: PDF文件损坏、权限问题、内存不足\n**检测**: `convert_pdf_to_images` 抛出异常\n**处理**:\n- 记录错误日志（包含文件名和异常信息）\n- 将PDF移动到 `NotInput` 目录\n- 返回 None\n- 主流程继续处理下一个PDF\n\n**用户影响**: 日志显示 `❌ 图片提取失败: paper1.pdf - 具体错误`\n\n#### 2. API调用失败\n**场景**: 网络错误、API配额不足、请求超时\n**检测**: `call_vision_api` 返回None或抛出异常\n**处理**:\n- 记录错误日志（包含PDF名称、错误类型）\n- 保留cache目录（用于后续重试）\n- 将PDF移动到 `NotInput` 目录\n- 记录到失败列表\n\n**用户影响**: 日志显示 `❌ API调用失败: paper1 - 网络超时`，cache保留在 `./cache/`\n\n#### 3. 归档失败\n**场景**: 磁盘空间不足、权限问题、zip创建失败\n**检测**: `shutil.make_archive` 抛出异常\n**处理**:\n- 捕获异常并记录警告日志\n- 保留cache目录（数据不丢失）\n- 继续处理流程（不中断）\n\n**用户影响**: 日志显示 `⚠️ 归档失败，保留cache: ./cache/paper1/ - 磁盘空间不足`\n\n#### 4. Cache目录已存在\n**场景**: 重复运行程序，cache未清理\n**检测**: `os.path.exists(cache_dir)`\n**处理**:\n- 覆盖已存在的cache（默认行为）\n- 或添加时间戳避免冲突（可选）\n\n**用户影响**: 日志显示 `⚠️ Cache已存在，覆盖: ./cache/paper1/`\n\n#### 5. 磁盘空间不足\n**场景**: 提取图片前检查磁盘空间\n**检测**: 提取前检查可用空间\n**处理**:\n- 预估所需空间（页数 × 单页大小）\n- 空间不足时提前报错\n- 不开始提取操作\n\n**用户影响**: 日志显示 `❌ 磁盘空间不足，需要 500MB，可用 100MB`\n\n## 测试策略\n\n### 单元测试\n\n#### 测试 `process_pdf`\n1. **测试 extract_only 模式**\n   - 输入：10页PDF\n   - 验证：返回cache_dir和image_paths\n   - 验证：cache目录存在且包含10个jpg文件\n\n2. **测试 full 模式**\n   - 输入：5页PDF\n   - 验证：返回result和cache_dir\n   - 验证：result包含预期数据结构\n\n3. **测试页数限制**\n   - 输入：30页PDF，max_pages=25\n   - 验证：只处理前25页\n   - 验证：日志显示警告信息\n\n4. **测试失败场景**\n   - 输入：损坏的PDF\n   - 验证：返回None\n   - 验证：PDF移动到NotInput\n\n#### 测试 `process_from_cache`\n1. **测试正常流程**\n   - 输入：有效的cache目录和image_paths\n   - 验证：返回API调用结果\n   - 验证：结果包含预期数据\n\n2. **测试API失败重试**\n   - 模拟API返回错误\n   - 验证：返回None\n   - 验证：cache目录仍存在\n\n3. **测试图片读取失败**\n   - 提供不存在的图片路径\n   - 验证：抛出清晰的错误\n\n#### 测试 `archive_cache`\n1. **测试正常归档**\n   - 输入：cache目录、PDF名称、批次号\n   - 验证：返回归档文件路径\n   - 验证：zip文件存在且包含所有图片\n   - 验证：cache目录已删除\n\n2. **测试归档失败**\n   - 模拟磁盘写错误\n   - 验证：返回None\n   - 验证：cache目录保留\n\n3. **测试重复归档**\n   - 同一cache归档两次\n   - 验证：第二次跳过（不重复创建）\n\n### 集成测试\n\n1. **完整流程测试**\n   - 输入：包含数据的PDF\n   - 验证：三个步骤都成功\n   - 验证：数据写入Excel\n   - 验证：cache被归档\n   - 验证：state.json正确更新\n\n2. **仅提取模式 + 独立第二阶段**\n   - 运行1：--mode extract_only\n   - 验证：创建cache，不调用API\n   - 运行2：--mode process_from_cache\n   - 验证：从cache调用API成功\n\n3. **失败重试场景**\n   - 运行1：完整流程，模拟API失败\n   - 验证：cache保留，PDF移动到NotInput\n   - 运行2：从cache重试（移动PDF回Input）\n   - 验证：成功处理\n\n### 性能测试\n\n1. **Cache性能**\n   - 测试不同页数PDF（1页、10页、25页、50页）\n   - 测量图片提取时间\n   - 测量cache归档时间\n\n2. **API调用时间对比**\n   - 测量完整流程时间（含图片提取）\n   - 测量从cache调用时间（仅API）\n   - 验证：第二阶段时间显著缩短\n\n3. **日志大小对比**\n   - 记录10个PDF的处理日志\n   - 对比优化前后的日志文件大小\n   - 目标：减少90%以上的日志大小\n\n### 端到端测试场景\n\n1. **场景：处理25篇论文**\n   - 批量处理25个PDF\n   - 验证：批次正确递增\n   - 验证：所有cache正确归档\n   - 验证：无内存泄漏\n\n2. **场景：混合长度的PDF**\n   - 包含1页、10页、30页的PDF\n   - 验证：页数限制正确应用\n   - 验证：cache大小合理\n\n3. **场景：API配额耗尽**\n   - 处理过程中API配额耗尽\n   - 验证：已处理的PDF正确记录\n   - 验证：未处理的PDF保留在Input\n   - 验证：可以从中断处继续\n\n## 部署与回滚\n\n### 部署步骤\n\n1. **备份现有代码**\n   ```bash\n   cp main.py main.py.backup\n   cp processing.py processing.py.backup\n   cp config.json config.json.backup\n   ```\n\n2. **更新代码**\n   - 修改 `process_pdf` 函数\n   - 新增 `process_from_cache` 函数\n   - 新增 `archive_cache` 函数（建议放在main.py）\n   - 优化 `call_vision_api` 日志\n\n3. **更新配置**\n   - 删除 `page_filtering` 配置块\n   - 添加 `max_pages` 配置（可选，默认25）\n   - 确认 `archive_destination` 路径正确\n\n4. **测试验证**\n   - 运行单元测试\n   - 处理1-2个测试PDF\n   - 验证日志可读性\n   - 验证cache和归档\n\n5. **完整部署**\n   - 运行完整批处理\n   - 监控日志输出\n   - 检查归档结果\n\n### 回滚方案\n\n如果出现问题：\n1. 恢复备份文件\n2. 清理cache目录（可选）\n3. 回滚config.json\n\n**回滚命令**:\n```bash\ncp main.py.backup main.py\ncp processing.py.backup processing.py\ncp config.json.backup config.json\n```\n\n### 监控指标\n\n部署后关注：\n- 平均处理时间（每个PDF）\n- API调用成功率\n- Cache归档成功率\n- 日志文件大小\n- 磁盘空间使用\n",
  "fileStats": {
    "size": 16279,
    "lines": 597,
    "lastModified": "2026-01-07T09:41:58.131Z"
  },
  "comments": []
}