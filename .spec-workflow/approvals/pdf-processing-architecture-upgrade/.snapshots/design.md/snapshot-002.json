{
  "id": "snapshot_1767707827564_gpww4okx6",
  "approvalId": "approval_1767707777353_hsp2athh0",
  "approvalTitle": "PDF Processing Architecture Upgrade Design",
  "version": 2,
  "timestamp": "2026-01-06T13:57:07.564Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# Design Document\n\n## Overview\n\nThis design upgrades the CFST Data Extractor from text-based PDF extraction to vision-based AI analysis using Gemini 3 Flash. The architecture shift enables more accurate table recognition, handles complex formatting, and implements adaptive scanning strategies based on document length.\n\n## Steering Document Alignment\n\n### Technical Standards (tech.md)\n- **OpenAI-Compatible APIs**: Uses same interface patterns as existing DeepSeek integration\n- **Configuration-Driven**: All parameters externalized to config.json following existing config management pattern\n- **Error Handling**: Maintains existing error handling patterns (try/catch, user-friendly messages)\n- **Modular Design**: Preserves single-responsibility principle across components\n\n### Project Structure (structure.md)\n- **Component Isolation**: New vision processing logic contained within processing.py\n- **API Abstraction**: AI provider details abstracted through OpenAI client interface\n- **Configuration Management**: Extends existing config.json structure without breaking backward compatibility\n\n## Code Reuse Analysis\n\n### Existing Components to Leverage\n- **main.py**: Core workflow orchestration remains unchanged (import → extract → validate → export)\n- **models.py**: Pydantic models (SpecimenData, ExtractionResult) reused as-is\n- **validation.py**: Physical validation formulas unchanged\n- **styling.py**: Excel export and formatting preserved\n- **Error handling patterns**: move_failed_file, move_excluded_file functions reused\n\n### Integration Points\n- **OpenAI Client**: Replace instructor-patched DeepSeek client with OpenAI-compatible Gemini client\n- **Configuration Loading**: Extend load_config() to include new API and processing settings\n- **PDF Processing Pipeline**: Replace extract_text_from_pdf() with vision-based process_pdf()\n- **Result Processing**: Unchanged - AI returns same JSON structure for backward compatibility\n\n## Architecture\n\nThe upgraded architecture shifts from text extraction to visual analysis:\n\n### Current Architecture (Text-Based)\n```\nPDF → pdfplumber → Text → optimize_text_for_extraction() → AI → JSON → Validation → Excel\n```\n\n### New Architecture (Vision-Based)\n```\nPDF → pdf2image → Images → Base64 Encoding → Vision AI → JSON → Validation → Excel\n                                      ↓\n                              Adaptive Page Strategy\n```\n\n### Modular Design Principles\n- **Single File Responsibility**: processing.py handles all PDF-to-image conversion and AI interaction\n- **Configuration Separation**: Zero hardcoded values - all settings from config.json\n- **Interface Consistency**: AI integration maintains same JSON input/output format\n- **Error Isolation**: Processing failures isolated from main workflow\n\n```mermaid\ngraph TD\n    A[main.py:main()] --> B[Load Config from config.json]\n    A --> C[Initialize OpenAI Client]\n    D[PDF files in files/] --> E[process_pdf() in processing.py]\n    E --> F{Page Count Check}\n    F -->|≤ threshold| G[Convert ALL pages to images]\n    F -->|> threshold| H[Convert first MAX pages]\n    G --> I[Encode images to Base64]\n    H --> I\n    I --> J[Build Vision API Payload]\n    J --> K[Send to Gemini AI]\n    K --> L[Parse JSON Response]\n    L --> M{is_valid check}\n    M -->|false| N[Move to Excluded/]\n    M -->|true| O[Extract specimen data]\n    O --> P[Validation via validation.py]\n    P --> Q[Export to Excel via styling.py]\n    N --> R[Continue batch processing]\n    Q --> R\n    R --> S{More PDFs?}\n    S -->|yes| D\n    S -->|no| T[Archive results]\n\n    subgraph \"Configuration\"\n        B\n        U[config.json]\n        B --- U\n    end\n\n    subgraph \"Vision Processing\"\n        E\n        V[pdf2image + PIL]\n        W[Base64 encoding]\n        E --- V\n        E --- W\n    end\n\n    subgraph \"AI Integration\"\n        C\n        J\n        K\n        X[OpenAI-compatible API]\n        C --- X\n        J --- X\n        K --- X\n    end\n```\n\n## Components and Interfaces\n\n### Component 1: Configuration Manager (Extended)\n**Purpose**: Centralize all settings including new vision processing parameters\n**Interfaces**:\n- `load_config()`: Returns expanded config dict with api_settings, processing_settings, paths\n- `validate_config()`: Checks required fields (api_key, base_url, model_name) and raises clear errors\n**Dependencies**: json, os\n**Reuses**: Existing config loading pattern from main.py\n\n### Component 2: Vision PDF Processor (New)\n**Purpose**: Convert PDF pages to images and interact with vision AI\n**Interfaces**:\n- `process_pdf(pdf_path: str) -> dict`: Main entry point, returns parsed JSON\n- `convert_pdf_to_images(pdf_path: str, page_limit: int) -> List[Image]`: Handles pdf2image conversion\n- `encode_image_to_base64(image) -> str`: Converts PIL Image to base64 string\n- `build_vision_payload(images: List, system_prompt: str) -> dict`: Constructs OpenAI vision format\n- `call_vision_api(payload: dict) -> dict`: Makes API call and handles errors\n**Dependencies**: pdf2image, PIL, base64, io, openai, config\n**Reuses**: SYSTEM_PROMPT constant from main.py, existing error handling patterns\n\n### Component 3: Adaptive Strategy Engine (New)\n**Purpose**: Determine scanning strategy based on document length\n**Interfaces**:\n- `get_page_count(pdf_path: str) -> int`: Uses pdf2image/pypdf to count pages\n- `should_scan_all_pages(page_count: int, threshold: int) -> bool`: Decision logic\n- `get_pages_to_process(page_count: int, config: dict) -> List[int]`: Returns page numbers\n**Dependencies**: pdf2image or pypdf\n**Reuses**: Processing thresholds from config.json\n\n## Data Models\n\n### Enhanced Config Structure\n```python\n{\n  \"api_settings\": {\n    \"api_key\": \"string\",  # Required: API key for Gemini\n    \"base_url\": \"string\",  # Required: OpenAI-compatible endpoint\n    \"model_name\": \"string\"  # Required: e.g., \"vertex-gemini-3-flash-preview\"\n  },\n  \"processing_settings\": {\n    \"short_paper_threshold\": \"int\",  # Pages ≤ this: scan all (default: 15)\n    \"max_scan_limit\": \"int\",  # Pages > threshold: scan this many (default: 10)\n    \"image_dpi\": \"int\"  # DPI for PDF to image conversion (default: 150)\n  },\n  \"paths\": {\n    \"windows_source_path\": \"string\",  # Optional: Windows PDF source\n    \"archive_destination\": \"string\",  # Optional: Archive location\n    \"manual_review_path\": \"string\"  # NEW: Failed extraction location\n  }\n}\n```\n\n### Vision API Payload Format\n```python\n{\n  \"model\": \"vertex-gemini-3-flash-preview\",\n  \"messages\": [\n    {\"role\": \"system\", \"content\": \"SYSTEM_PROMPT\"},\n    {\n      \"role\": \"user\",\n      \"content\": [\n        {\"type\": \"text\", \"text\": \"Extract data from these pages...\"},\n        {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/jpeg;base64,...\"}},\n        {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/jpeg;base64,...\"}},\n        ...\n      ]\n    }\n  ],\n  \"temperature\": 0.1,\n  \"max_tokens\": 8192\n}\n```\n\n## Error Handling\n\n### Error Scenario 1: Missing Dependencies\n**Description**: poppler not installed for pdf2image\n**Handling**:\n- Use `shutil.which()` to check for `pdftoppm` or `pdfinfo`\n- Raise clear error with Chinese installation instructions:\n  - Ubuntu/Debian: `sudo apt-get install poppler-utils`\n  - Windows: Download from https://github.com/oschwartz10612/poppler-windows\n- Halt application startup with descriptive error message\n\n**User Impact**: Clear actionable error message prevents cryptic failures\n\n### Error Scenario 2: Invalid API Configuration\n**Description**: Missing or invalid API key/base_url/model_name\n**Handling**:\n- Validate config on startup: check all required fields present\n- Verify API connectivity with test call (optional)\n- Raise ValueError with specific missing field names\n\n**User Impact**: Prevents runtime API failures, clear configuration guidance\n\n### Error Scenario 3: PDF Processing Failure\n**Description**: Corrupted PDF, password-protected, or unsupported format\n**Handling**:\n- Wrap pdf2image calls in try/except\n- On failure: log warning, move to NotInput/, continue batch processing\n- Record error reason in log for debugging\n\n**User Impact**: Batch processing continues, failed files isolated for manual review\n\n### Error Scenario 4: Zero Data Extraction\n**Description**: AI returns empty Group_A/B/C arrays\n**Handling**:\n- Check if all groups are empty AND is_valid=true\n- Log yellow warning: \"⚠️ [Filename] 未提取到数据...\"\n- Move file to manual_review_path/ (create if not exists)\n- Continue batch processing\n\n**User Impact**: Transparent extraction failures, separate location for edge cases\n\n### Error Scenario 5: API Rate Limits/Network Errors\n**Description**: API timeout, rate limiting, network issues\n**Handling**:\n- Implement exponential backoff retry logic (3 attempts)\n- On persistent failure: log error, move to NotInput/, continue\n- Respect rate limit headers if provided by API\n\n**User Impact**: Graceful degradation, automatic retry where appropriate\n\n## Testing Strategy\n\n### Unit Testing\n- **Configuration Loading**: Test all config scenarios (missing fields, invalid values)\n- **Image Conversion**: Test pdf2image with various PDF formats (single page, multi-page, corrupted)\n- **Base64 Encoding**: Verify image encoding/decoding roundtrip\n- **Page Count Detection**: Test accuracy across different PDF types\n- **Adaptive Strategy**: Verify logic for different page counts and thresholds\n\n**Key components to test**:\n- `process_pdf()` - main processing logic\n- `convert_pdf_to_images()` - image conversion with page limits\n- `get_page_count()` - page counting accuracy\n- Configuration validation functions\n\n### Integration Testing\n- **End-to-End Vision Flow**: PDF → Images → API → JSON (with test PDFs)\n- **Configuration Integration**: Verify config values flow through entire pipeline\n- **Error Handling**: Test each error scenario with appropriate test files\n- **Batch Processing**: Multiple PDFs with mixed success/failure cases\n\n**Key flows to test**:\n- Short paper full scanning (≤15 pages)\n- Long paper truncated scanning (>15 pages)\n- Zero-data detection and manual review routing\n- Invalid API config error handling\n- Poppler missing error handling\n\n### End-to-End Testing\n**User scenarios to test**:\n1. **Normal Processing**: Standard CFST paper with tables → Extracted data in Excel\n2. **Short Paper**: 10-page paper → All pages scanned, data extracted\n3. **Long Paper**: 50-page paper → Only first 10 pages scanned, warning logged\n4. **No Data Paper**: Paper without CFST data → Moved to Manual_Review/, warning displayed\n5. **Corrupted PDF**: Invalid PDF → Moved to NotInput/, error logged, processing continues\n6. **Missing Config**: Invalid API key → Clear error on startup, application exits\n7. **Missing Poppler**: Poppler not installed → Clear installation instructions, application exits\n\n**Test data needs**:\n- Valid CFST papers (3-5 samples)\n- Short papers (<15 pages)\n- Long papers (>15 pages)\n- Papers without extractable data\n- Corrupted/invalid PDFs\n- Password-protected PDFs\n",
  "fileStats": {
    "size": 11011,
    "lines": 275,
    "lastModified": "2026-01-06T13:56:11.639Z"
  },
  "comments": []
}