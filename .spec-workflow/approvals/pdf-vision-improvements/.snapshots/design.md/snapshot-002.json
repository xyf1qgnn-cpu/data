{
  "id": "snapshot_1767714319616_4lyw586lo",
  "approvalId": "approval_1767714109056_t3tb98qn5",
  "approvalTitle": "AI视觉处理改进设计 - JSON约束和智能页面筛选",
  "version": 2,
  "timestamp": "2026-01-06T15:45:19.616Z",
  "trigger": "revision_requested",
  "status": "pending",
  "content": "# Design Document\n\n## Overview\n\n本设计针对CFST数据提取系统的两大核心问题提供技术解决方案：\n\n1. **Token溢出问题**：通过强化Prompt约束，强制AI模型输出极简JSON格式（reason字段为双引号或最多10个词）\n2. **页面浪费问题**：实现智能页面筛选机制，仅处理最可能包含数据的页面\n\n解决方案采用两阶段架构设计，在保留现有视觉处理流程的基础上，新增轻量级的文本侦察阶段，实现成本与精度的平衡。\n\n## Steering Document Alignment\n\n### Technical Standards\n本设计遵循以下技术标准：\n- **模块化设计**：智能筛选功能独立封装，与视觉处理模块解耦\n- **配置驱动**：所有阈值、权重、关键词列表均通过config.json配置\n- **向后兼容**：不修改现有处理流程，新增能力作为可选优化\n- **错误隔离**：阶段一失败自动回退到阶段二，确保系统可用性\n\n### Project Structure\n设计遵循现有项目结构：\n- `processing.py`：新增智能筛选函数（保持原有视觉处理逻辑不变）\n- `config.json`：扩展配置项，包含评分权重、关键词列表等\n- `main.py`：更新System Prompt（不改变核心工作流程）\n\n## Code Reuse Analysis\n\n### Existing Components to Leverage\n- **`process_pdf()`函数**：现有视觉处理的主入口，扩展为支持选择性页面处理\n- **`config.json`结构**：已有的嵌套配置结构，新增`page_filtering`配置段\n- **`SYSTEM_PROMPT`**：现有系统提示词，增加JSON输出约束说明\n- **OpenAI客户端**：已初始化的API客户端，接口无需修改\n\n### Integration Points\n- **`processing.py`入口**：新增`get_smart_pages_to_process()`函数，返回筛选后的页面列表\n- **`config_manager.py`**：新增配置验证规则，确保评分权重合法\n- **主处理流程**：在`process_pdf()`内增加阶段一（文本侦察），必要时跳过阶段二\n\n## Architecture\n\n### 两阶段处理流程图\n\n```mermaid\ngraph TD\n    A[PDF文件] --> B{页数检查}\n    B -->|<10页| C[跳过筛选]\n    B -->|>10页| D[阶段一：文本侦察]\n    C --> H[转换所有页为图片]\n    D --> E[按关键词打分]\n    E --> F[选择Top N页]\n    F --> G[阶段二：视觉提取]\n    H --> G\n    G --> I[AI处理]\n    I --> J[返回JSON结果]\n\n    style D fill:#e3f2fd\n    style G fill:#e8f5e9\n    style F fill:#fff3e0\n```\n\n### 智能页面筛选流程\n\n```mermaid\ngraph TD\n    A[输入PDF] --> B[提取所有页文本]\n    B --> C[初始化权重]\n    C --> D{遍历每页}\n    D --> E[检测表格标题]\n    E -->|匹配| F[+10分]\n    D --> G[检测数据词汇]\n    G -->|匹配| H[+5分]\n    D --> I[检测参考文献]\n    I -->|匹配| J[-5分]\n    D --> K[无匹配]\n    K --> L[+1分]\n    F --> M[添加到得分表]\n    H --> M\n    J --> M\n    L --> M\n    M --> D\n    D --> N{完成所有页?}\n    N -->|否| D\n    N -->|是| O[排序页面得分]\n    O --> P[选择Top N页]\n    P --> Q[强制包含第1页]\n    Q --> R[返回页面列表 + 分数]\n\n    style A fill:#f3e5f5\n    style R fill:#e1f5e1\n```\n\n### Modular Design Principles\n\n**单文件职责**：\n- `processing.py`：只负责PDF处理和页面筛选（规模约600行）\n- `config_manager.py`：只负责配置验证（规模约200行）\n- `main.py`：只负责流程编排和日志（保持现有规模）\n\n**组件隔离**：\n- 智能筛选功能独立成`get_smart_pages_to_process()`函数，可单独测试\n- 评分算法独立成`score_page_content()`函数，便于调整权重\n- 配置解析隔离，确保新增配置不会影响旧配置\n\n**服务层分离**：\n- 数据访问层：pdfplumber提取文本（阶段一）、pdf2image转换图片（阶段二）\n- 业务逻辑层：页面评分算法、页面选择逻辑\n- API调用层：OpenAI/Gemini视觉处理（与现有流程一致）\n\n## Components and Interfaces\n\n### Component 1: PDF Text Extraction (阶段一基础)\n\n**Purpose**：使用pdfplumber快速提取PDF每页文本内容，用于评分\n\n**Interfaces**：\n```python\ndef extract_page_texts(pdf_path: str) -> Dict[int, str]:\n    \"\"\"\n    提取PDF所有页面的文本内容\n\n    参数：\n        pdf_path: PDF文件路径\n\n    返回：\n        字典 {页码（从1开始）: 文本内容}\n\n    异常：\n        pdfplumber失败 -> 返回空字典，触发回退机制\n    \"\"\"\n```\n\n**Dependencies**：\n- `pdfplumber`: 文本提取库\n- `os`: 文件路径操作\n\n**Reuses**：\n- 现有的pdfplumber依赖（已在requirements.txt中）\n\n### Component 2: Page Scoring Algorithm (核心评分逻辑)\n\n**Purpose**：实现页面内容评分算法，识别高价值页面\n\n**Interfaces**：\n```python\ndef score_page_content(text: str, config: dict) -> int:\n    \"\"\"\n    计算单页内容的评分\n\n    参数：\n        text: 页面文本内容\n        config: 包含关键词权重的配置\n\n    返回：\n        整数得分（可能为负数）\n\n    评分逻辑：\n        - 表格标题匹配：+10分（可配置）\n        - 数据词汇匹配：+5分（可配置）\n        - 参考文献页：-5分（可配置）\n        - 普通文本：+1分\n    \"\"\"\n\ndef get_smart_pages_to_process(pdf_path: str, config: dict) -> Tuple[List[int], str, List[Dict]]:\n    \"\"\"\n    主函数：返回需要处理的页面列表\n\n    参数：\n        pdf_path: PDF文件路径\n        config: 配置对象\n\n    返回：\n        Tuple包含：\n        - 页面编号列表（从1开始）\n        - 策略描述字符串（用于日志）\n        - 调试信息列表（包含页面分数和选择原因）\n    \"\"\"\n```\n\n**Dependencies**：\n- `re`: 正则表达式匹配\n- `typing`: 类型注解\n\n**Reuses**：\n- config.json中定义的关键词列表\n- 现有的日志系统记录页面选择逻辑\n\n### Component 3: Prompt Optimization (JSON约束)\n\n**Purpose**：优化SYSTEM_PROMPT，强制AI输出符合约束的JSON格式\n\n**Interfaces**：\n```python\n# 在main.py中修改SYSTEM_PROMPT常量\nSYSTEM_PROMPT = \"\"\"\n...  # 保持原有内容\n\n# 4. Output Format (JSON Only - STRICT RULES)\n\n**CRITICAL OUTPUT REQUIREMENTS:**\n\n1. **PURE JSON ONLY**: Output ONLY a raw JSON string. DO NOT wrap...\n2. **reason FIELD CONSTRAINT**: The `reason` field MUST be either:\n   - An empty string: `\"\"` (preferred for valid data)\n   - OR a brief explanation with MAXIMUM 10 words\n   - ...\n\"\"\"\n```\n\n**Dependencies**：\n- `main.py`: 包含SYSTEM_PROMPT定义\n\n**Reuses**：\n- 现有的OpenAI客户端配置\n- 现有的JSON解析逻辑（增加截断检测）\n\n### Component 4: Configuration Schema Extension\n\n**Purpose**：扩展config.json结构，支持页面筛选配置\n\n**数据模型**：\n```json\n{\n  \"api_settings\": {...},\n  \"processing_settings\": {\n    \"short_paper_threshold\": 10,\n    \"max_scan_limit\": 10,\n    \"enable_smart_filtering\": true,  // 新增：启用智能筛选\n    \"page_filtering\": {  // 新增评分配置\n      \"table_title_weight\": 10,\n      \"data_keyword_weight\": 5,\n      \"reference_weight\": -5,\n      \"table_patterns\": [\n        \"Table\\\\s+\\\\d+\",\n        \"Tab\\\\.\\\\s+\\\\d+\"\n      ],\n      \"data_keywords\": [\n        \"Specimen\",\n        \"Experimental\",\n        \"kN\",\n        \"mm\",\n        \"B/t\",\n        \"D/t\"\n      ],\n      \"reference_patterns\": [\n        \"References\",\n        \"Bibliography\",\n        \"REFERENCES\"\n      ],\n      \"max_filtered_pages\": 8  // 筛选后最多处理的页数\n    }\n  },\n  \"paths\": {...}\n}\n```\n\n## Data Models\n\n### Page Scoring Result\n```python\n@dataclass\nclass PageScore:\n    \"\"\"单页评分结果\"\"\"\n    page_number: int      # 页码（从1开始）\n    score: int            # 总得分\n    matched_keywords: List[str]  # 匹配的关键词列表\n    is_table_page: bool   # 是否包含表格\n    is_reference: bool    # 是否为参考文献页\n```\n\n### Smart Filtering Config\n```python\n@dataclass\nclass PageFilteringConfig:\n    \"\"\"页面筛选配置\"\"\"\n    enabled: bool = True  # 是否启用智能筛选\n    table_title_weight: int = 10\n    data_keyword_weight: int = 5\n    reference_weight: int = -5\n    max_filtered_pages: int = 8\n    table_patterns: List[str] = None\n    data_keywords: List[str] = None\n    reference_patterns: List[str] = None\n\n    def __init__(self, **kwargs):\n        # 提供默认值\n        self.table_patterns = [\n            r'Table\\\\s+\\\\d+',\n            r'Tab\\\\.\\\\s+\\\\d+',\n            r'表\\\\s+\\\\d+'\n        ]\n        self.data_keywords = [\n            'Specimen', 'Experimental', 'kN', 'mm',\n            'B/t', 'D/t', 'fc', 'fy', 'D', 't'\n        ]\n        self.reference_patterns = [\n            r'References',\n            r'Bibliography',\n            r'REFERENCES',\n            r'参考文献'\n        ]\n        # 从kwargs更新\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n```\n\n### Processing Debug Info\n```python\n@dataclass\nclass FilteringDebugInfo:\n    \"\"\"用于日志和调试的详细信息\"\"\"\n    total_pages: int\n    filtered_pages: List[int]\n    page_scores: List[PageScore]\n    strategy: str\n    processing_time_ms: float\n```\n\n## Error Handling\n\n### Error Scenario 1: pdfplumber提取失败\n\n**描述**：pdfplumber失败或无法提取文本，阶段一无法完成\n\n**处理方式**：\n```python\ntry:\n    page_texts = extract_page_texts(pdf_path)\n    if not page_texts:  # 提取失败为空\n        logger.warning(f\"文本提取失败，回退到简单截断策略: {pdf_path}\")\n        return list(range(1, min(page_count, max_scan_limit) + 1)), \"回退到截断策略\", []\nexcept Exception as e:\n    logger.error(f\"文本侦察阶段异常: {str(e)}\")\n    # 继续流程，但标记为回退状态\n```\n\n**用户影响**：\n- 系统降级处理（性能影响可忽略）\n- 日志中记录降级原因，无需用户干预\n\n### Error Scenario 2: JSON解析失败（截断）\n\n**描述**：AI返回的JSON因token溢出被截断，无法解析\n\n**处理策略**：\n```python\ntry:\n    response = client.chat.completions.create(...)\n    content = response.choices[0].message.content\n    # 检测是否可能是截断的JSON\n    if '\\\"Group_A\\\": [' in content and not content.rstrip().endswith('}'):\n        logger.error(f\"检测到截断JSON: {pdf_path}\")\n        # 移除包含Markdown代码块标记的错误内容\n    result = json.loads(content)\nexcept json.JSONDecodeError as e:\n    logger.error(f\"JSON解析失败: {str(e)}, 文件: {pdf_path}\")\n    # 移动到Manual_Review目录\n    move_to_manual_review(pdf_path, f\"JSON解析失败: {str(e)}\")\n    # 返回结果，继续批量处理\n    return {\"is_valid\": False, \"reason\": \"JSON Parsing Error\"}\n```\n\n**日志记录**：\n```\n[ERROR] JSON解析失败 - file: paper_2024.pdf\n错误详情: Unterminated string starting at: line 29 column 7\n截断内容: {\"is_valid\": true, \"reason\": \"The paper provides experimental data for eccentrically loaded...\n操作: 文件已移动到 Manual_Review/paper_2024.pdf\n```\n\n**用户影响**：\n- 打印红色错误消息\n- 文件被移动到Manual_Review目录\n- 批量处理继续，不影响其他文件\n\n### Error Scenario 3: 关键词配置错误\n\n**描述**：config.json中的关键词模式无效，导致匹配失败\n\n**处理方式**：\n```python\ntry:\n    pattern = re.compile(keyword_pattern)\nexcept re.error:\n    logger.warning(f\"无效的正则表达式模式: {keyword_pattern}, 跳过该模式\")\n    continue  # 跳过无效模式，其他模式继续匹配\n```\n\n**用户影响**：\n- 部分功能降级（某些关键词失效）\n- 日志中记录无效模式，便于调试\n- 核心功能不受影响\n\n### Error Scenario 4: 页面筛选为空\n\n**描述**：所有页面得分均为负数，筛选后无页面可选\n\n**处理策略**：\n```python\nfiltered_pages = [page for page, score in scored_pages if score > 0]\nif not filtered_pages:\n    logger.warning(f\"筛选后无有效页面，回退到默认页: {pdf_path}\")\n    # 选择得分最高的页面（即使为负），确保至少处理1页\n    filtered_pages = [scored_pages[0][0]]  # 加第一页\n```\n\n**用户影响**：\n- 处理效率降低（可能处理低价值页面）\n- 日志记录回退逻辑，提醒检查关键词配置\n\n## Testing Strategy\n\n### 单元测试\n\n**页面评分算法测试**：\n```python\ndef test_score_page_with_table():\n    text = \"Table 1 shows experimental results for Specimen C-1\"\n    score = score_page_content(text, DEFAULT_CONFIG)\n    assert score >= 15  # Table (+10) + Specimen (+5)\n\ndef test_score_reference_page():\n    text = \"References: [1] Smith et al. (2020)\"\n    score = score_page_content(text, DEFAULT_CONFIG)\n    assert score == -4  # Reference (-5) + Base (+1)\n\ndef test_score_empty_page():\n    text = \"\"\n    score = score_page_content(text, DEFAULT_CONFIG)\n    assert score == 0  # No content = No score\n```\n\n**页面选择逻辑测试**：\n```python\ndef test_select_top_pages():\n    scores = [(1, 20), (2, 5), (3, 15), (4, 25), (5, 10)]\n    selected = select_top_pages(scores, max_pages=3, include_first=True)\n    assert selected == [1, 4, 3]  # 第1页强制包含，然后选4和3\n\ndef test_empty_scores_fallback():\n    scores = []\n    selected = select_top_pages(scores, max_pages=5)\n    assert selected == []  # 空列表，触发回退逻辑\n```\n\n### 集成测试\n\n**两阶段处理完整流程**：\n```python\ndef test_two_phase_processing():\n    # 准备测试PDF（20页，包含表格在第5、12、18页）\n    pdf_path = \"test_long_paper.pdf\"\n    config = load_config_with_smart_filtering()\n\n    # 执行两阶段处理\n    pages, description, debug_info = get_smart_pages_to_process(pdf_path, config)\n\n    # 验证结果\n    assert len(pages) <= 8  # 不超过最大限制\n    assert 1 in pages  # 第1页强制包含\n    assert 5 in pages or 12 in pages or 18 in pages  # 至少选中一个含表格页\n```\n\n**JSON约束效果测试**：\n```python\ndef test_json_reason_field_constraint():\n    system_prompt = generate_system_prompt_with_constraints()\n\n    # 测试有效响应\n    valid_response = '{\"is_valid\": true, \"reason\": \"\", \"Group_A\": []}'\n    result = parse_ai_response(valid_response)\n    assert result.is_valid == True\n\n    # 测试无效响应（reason过长）\n    long_reason = 'A' * 100  # 100个字符\n    invalid_response = f'{{\"is_valid\": true, \"reason\": \"{long_reason}\"}}'\n    result = parse_ai_response(invalid_response)\n    assert result.reason_length <= 10  # 被截断或记录警告\n```\n\n### 端到端测试\n\n**典型长论文场景**：\n- 测试PDF：30页，试验数据在第5-8页（表格），第20页（结果）\n- 预期选择：第1、5、6、7、8、20页（约6页）\n- 成本节省：从10页减少到6页（40%节省）\n- 成功率：所有试验数据都应被提取\n\n**异常场景测试**：\n1. 使用失效的pdfplumber（模拟提取失败），验证回退策略\n2. 使用无效关键词配置（模拟正则错误），验证部分降级\n3. 使用被截断的AI响应，验证JSON解析错误处理\n\n**性能基准测试**：\n- 100页PDF的文本侦察时间应<200ms\n- 批量处理10个PDF（平均20页）的总时间影响<5%\n\n### 回归测试\n\n- 短论文（≤10页）必须保持全量扫描行为\n- 现有Excel数据格式必须保持不变\n- 零数据检测（空Group_A/B/C）逻辑不得被破坏\n",
  "fileStats": {
    "size": 15199,
    "lines": 503,
    "lastModified": "2026-01-06T15:41:37.009Z"
  },
  "comments": []
}